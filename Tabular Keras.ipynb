{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, BatchNormalization, Dropout, Input, Flatten\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance(frame, col='hab_lbl', factor=1):\n",
    "    max_size = frame[col].value_counts().max()\n",
    "    lst = [frame]\n",
    "    for class_index, group in frame.groupby(col):\n",
    "        lst.append(group.sample(int((max_size-len(group)) / factor), replace=True))\n",
    "    frame_new = pd.concat(lst)\n",
    "    \n",
    "    return frame_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the \"giveaway\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset-rocky-no-STemp.csv')\n",
    "df = df.drop('P. Habitable', axis=1)\n",
    "#y = df['hab_lbl']\n",
    "#df.drop('hab_lbl', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1713, 42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = df.columns[np.where(df.dtypes == 'int64')]\n",
    "cat_vars = cat_vars.tolist()\n",
    "cat_vars.remove('hab_lbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = df.columns[np.where(df.dtypes != 'int64')].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the cateogrical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_vars:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    df[cat_col] = label_encoders[cat_col].fit_transform(df[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P. Zone Class',\n",
       " 'P. Mass Class',\n",
       " 'P. Composition Class',\n",
       " 'P. Atmosphere Class']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebalance only the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = rebalance(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3492, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['hab_lbl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['hab_lbl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/.local/lib/python3.5/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop('hab_lbl', axis=1, inplace=True)\n",
    "test_df.drop('hab_lbl', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P. Zone Class</th>\n",
       "      <th>P. Mass Class</th>\n",
       "      <th>P. Composition Class</th>\n",
       "      <th>P. Atmosphere Class</th>\n",
       "      <th>P. Min Mass (EU)</th>\n",
       "      <th>P. Mass (EU)</th>\n",
       "      <th>P. Radius (EU)</th>\n",
       "      <th>P. Density (EU)</th>\n",
       "      <th>P. Gravity (EU)</th>\n",
       "      <th>P. Esc Vel (EU)</th>\n",
       "      <th>...</th>\n",
       "      <th>S. Appar Mag</th>\n",
       "      <th>S. Mag from Planet</th>\n",
       "      <th>S. Size from Planet (deg)</th>\n",
       "      <th>S. Hab Zone Min (AU)</th>\n",
       "      <th>S. Hab Zone Max (AU)</th>\n",
       "      <th>P. HZD</th>\n",
       "      <th>P. HZC</th>\n",
       "      <th>P. HZA</th>\n",
       "      <th>P. HZI</th>\n",
       "      <th>P. ESI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.217914</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>13.747447</td>\n",
       "      <td>-29.7</td>\n",
       "      <td>3.3814</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.217914</td>\n",
       "      <td>24.12</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.66</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.14</td>\n",
       "      <td>...</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>-29.2</td>\n",
       "      <td>2.8653</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.748</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18.217914</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>-28.8</td>\n",
       "      <td>2.4066</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18.217914</td>\n",
       "      <td>18.31</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.82</td>\n",
       "      <td>...</td>\n",
       "      <td>13.747447</td>\n",
       "      <td>-32.5</td>\n",
       "      <td>6.6652</td>\n",
       "      <td>1.203</td>\n",
       "      <td>2.809</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18.217914</td>\n",
       "      <td>5.54</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.80</td>\n",
       "      <td>...</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>5.8735</td>\n",
       "      <td>0.895</td>\n",
       "      <td>2.096</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P. Zone Class  P. Mass Class  P. Composition Class  P. Atmosphere Class  \\\n",
       "752               2              4                     3                    3   \n",
       "1154              2              2                     3                    1   \n",
       "252               2              4                     3                    2   \n",
       "292               2              2                     3                    2   \n",
       "987               2              2                     3                    2   \n",
       "\n",
       "      P. Min Mass (EU)  P. Mass (EU)  P. Radius (EU)  P. Density (EU)  \\\n",
       "752          18.217914          0.53            0.86             0.83   \n",
       "1154         18.217914         24.12            2.44             1.66   \n",
       "252          18.217914          1.65            1.21             0.93   \n",
       "292          18.217914         18.31            2.30             1.51   \n",
       "987          18.217914          5.54            1.70             1.12   \n",
       "\n",
       "      P. Gravity (EU)  P. Esc Vel (EU)  ...  S. Appar Mag  S. Mag from Planet  \\\n",
       "752              0.72             0.79  ...     13.747447               -29.7   \n",
       "1154             4.05             3.14  ...     15.600000               -29.2   \n",
       "252              1.12             1.17  ...     15.600000               -28.8   \n",
       "292              3.47             2.82  ...     13.747447               -32.5   \n",
       "987              1.91             1.80  ...     14.800000               -32.2   \n",
       "\n",
       "      S. Size from Planet (deg)  S. Hab Zone Min (AU)  S. Hab Zone Max (AU)  \\\n",
       "752                      3.3814                 0.286                 0.707   \n",
       "1154                     2.8653                 0.301                 0.748   \n",
       "252                      2.4066                 0.268                 0.665   \n",
       "292                      6.6652                 1.203                 2.809   \n",
       "987                      5.8735                 0.895                 2.096   \n",
       "\n",
       "      P. HZD  P. HZC  P. HZA  P. HZI  P. ESI  \n",
       "752    -1.92   -0.18   -1.05    0.31    0.38  \n",
       "1154   -1.80   -0.11    1.15    0.32    0.36  \n",
       "252    -1.70   -0.17   -0.62    0.35    0.47  \n",
       "292    -2.35   -0.12    0.03    0.30    0.25  \n",
       "987    -2.32   -0.15   -0.56    0.29    0.28  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert outputs to one-hot encoded outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(np.array(y))\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_inps = [list(train_df[x]) for x in cat_vars]\n",
    "cont_inp = np.array(list(train_df[cont_vars]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3495, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[cont_vars].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3495, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat_inps = [Input(shape=(1,)) for _ in cat_inps]\n",
    "model_cont_inp = Input(shape=(1, 37), name='cont_inp')\n",
    "\n",
    "embeddings = [Embedding(input_dim=len(np.unique(x)),\n",
    "                        output_dim=round(1.6 * len(np.unique(x)) ** 0.56)\n",
    "                       )(y) for x, y in zip(cat_inps, model_cat_inps)]\n",
    "bn1 = BatchNormalization(name='first_bn')(model_cont_inp)\n",
    "\n",
    "concat = keras.layers.concatenate([*embeddings, bn1], name='concatenate')\n",
    "\n",
    "relu = Dense(5, activation='relu', name='dense1')(concat)\n",
    "bn = BatchNormalization(name='bn1')(relu)\n",
    "drop = Dropout(0.2, name='dropout1')(bn)\n",
    "\n",
    "relu = Dense(5, activation='relu', name='dense2')(drop)\n",
    "bn = BatchNormalization()(relu)\n",
    "drop = Dropout(0.2)(bn)\n",
    "\n",
    "flat = Flatten()(drop)\n",
    "out = Dense(3, activation='softmax', name='dense3')(flat)\n",
    "\n",
    "model = Model(inputs=[*model_cat_inps, model_cont_inp], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cont_inp (InputLayer)           (None, 1, 37)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 3)         12          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 4)         24          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 2)         4           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 3)         12          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "first_bn (BatchNormalization)   (None, 1, 37)        148         cont_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 49)        0           embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 first_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 1, 5)         250         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 1, 5)         20          dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 1, 5)         0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 1, 5)         30          dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 5)         20          dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 5)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 3)            18          flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 538\n",
      "Trainable params: 444\n",
      "Non-trainable params: 94\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LipschitzLR code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_5:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_6:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_7:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_8:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'cont_inp_1:0' shape=(?, 1, 37) dtype=float32>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function(model.inputs, [model.layers[-2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3495)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cat_inps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, _):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    Kz = func([*cat_inps, np.array(train_df[cont_vars]).reshape(3495, 1, 37)])\n",
    "    print(Kz)\n",
    "    \n",
    "    Kz = np.linalg.norm(Kz)\n",
    "\n",
    "    K_ = (2. * Kz) / (3. * batch_size)\n",
    "    lr = 1 / K_\n",
    "    lrs.append(lr)\n",
    "    print('Epoch', epoch, 'LR =', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(SGD(0.1), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2\n\t [[{{node concatenate_1/concat}} = ConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embedding_lookup, embedding_6/embedding_lookup, embedding_7/embedding_lookup, embedding_8/embedding_lookup, first_bn_1/cond/Merge, concatenate_1/concat/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-dcb47104ce2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcat_inps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3495\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful_metric_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# new API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# old API for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-de7e7cdbe2a1>\u001b[0m in \u001b[0;36mlr_schedule\u001b[0;34m(epoch, _)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mKz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcat_inps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcont_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3495\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2\n\t [[{{node concatenate_1/concat}} = ConcatV2[N=5, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_5/embedding_lookup, embedding_6/embedding_lookup, embedding_7/embedding_lookup, embedding_8/embedding_lookup, first_bn_1/cond/Merge, concatenate_1/concat/axis)]]"
     ]
    }
   ],
   "source": [
    "model.fit(x=[*cat_inps, np.array(train_df[cont_vars]).reshape(3495, 1, 37)], y=y, epochs=1, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_3:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_4:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'cont_inp:0' shape=(?, 1, 37) dtype=float32>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7efb742630f0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7efb7425ab00>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7efb7425a940>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7efb7425abe0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7efb74273208>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7efb6fdfd390>,\n",
       " <keras.layers.embeddings.Embedding at 0x7efb6fdfd2e8>,\n",
       " <keras.layers.embeddings.Embedding at 0x7efb6fbe3b00>,\n",
       " <keras.layers.embeddings.Embedding at 0x7efb6fc9ddd8>,\n",
       " <keras.layers.embeddings.Embedding at 0x7efb74272940>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7efb6fd90c18>,\n",
       " <keras.layers.merge.Concatenate at 0x7efb6fbf8da0>,\n",
       " <keras.layers.core.Dense at 0x7efb6fbb43c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7efb6fa88c88>,\n",
       " <keras.layers.core.Dropout at 0x7efb6fa88518>,\n",
       " <keras.layers.core.Dense at 0x7efb6fa52f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7efb74272320>,\n",
       " <keras.layers.core.Dropout at 0x7efb6f996f60>,\n",
       " <keras.layers.core.Flatten at 0x7efb74263828>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(x=[*cat_inps, np.array(train_df[cont_vars]).reshape(3495, 1, 37)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3495, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(x=[*cat_inps, np.array(train_df[cont_vars]).reshape(3495, 1, 37)]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(41,))\n",
    "\n",
    "bn1 = BatchNormalization(name='first_bn')(inp)\n",
    "relu = Dense(5, activation='relu', name='dense1')(bn1)\n",
    "drop1 = Dropout(0.2, name='dropout1')(relu)\n",
    "\n",
    "bn = BatchNormalization(name='bn1')(drop1)\n",
    "relu = Dense(5, activation='relu', name='dense2')(bn)\n",
    "drop2 = Dropout(0.2)(relu)\n",
    "\n",
    "interm = keras.layers.Concatenate()([drop1, drop2])\n",
    "\n",
    "bn = BatchNormalization(name='bn2')(interm)\n",
    "relu = Dense(5, activation='relu', name='dense3')(bn)\n",
    "drop = Dropout(0.2)(relu)\n",
    "\n",
    "interm = keras.layers.Concatenate()([drop, drop2])\n",
    "\n",
    "bn = BatchNormalization()(interm)\n",
    "out = Dense(3, activation='softmax', name='dense4')(bn)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([model.layers[0].input], [model.layers[-2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 41)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_bn (BatchNormalization)   (None, 41)           164         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 5)            210         first_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 5)            0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 5)            20          dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 5)            30          bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5)            0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10)           0           dropout1[0][0]                   \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 10)           40          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 5)            55          bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5)            0           dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 10)           0           dropout_2[0][0]                  \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10)           40          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense4 (Dense)                  (None, 3)            33          batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 592\n",
      "Trainable params: 460\n",
      "Non-trainable params: 132\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309925.3947118223"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3492, 41), (3492,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    Kz = 0.\n",
    "    for i in range((len(x_train) - 1) // batch_size + 1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i:end_i]\n",
    "    \n",
    "        activ = np.linalg.norm(func([xb]))\n",
    "        if activ > Kz:\n",
    "            Kz = activ\n",
    "\n",
    "    K_ = (2. * Kz) / (3. * batch_size)\n",
    "    lr = 1 / K_\n",
    "    lrs.append(lr)\n",
    "    print('Epoch', epoch, 'LR =', lr)\n",
    "    return lr\n",
    "    #return K_ / np.sqrt(epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(SGD(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3492 samples, validate on 514 samples\n",
      "Epoch 1/10\n",
      "3492/3492 [==============================] - 3s 887us/step - loss: 0.9644 - acc: 0.5444 - val_loss: 0.3834 - val_acc: 0.9611\n",
      "Epoch 2/10\n",
      "3492/3492 [==============================] - 1s 194us/step - loss: 0.6856 - acc: 0.6841 - val_loss: 0.2307 - val_acc: 0.9689\n",
      "Epoch 3/10\n",
      "3492/3492 [==============================] - 1s 198us/step - loss: 0.5589 - acc: 0.7646 - val_loss: 0.1823 - val_acc: 0.9747\n",
      "Epoch 4/10\n",
      "3492/3492 [==============================] - 1s 202us/step - loss: 0.5013 - acc: 0.7973 - val_loss: 0.1659 - val_acc: 0.9825\n",
      "Epoch 5/10\n",
      "3492/3492 [==============================] - 1s 196us/step - loss: 0.4567 - acc: 0.8204 - val_loss: 0.1422 - val_acc: 0.9844\n",
      "Epoch 6/10\n",
      "3492/3492 [==============================] - 1s 200us/step - loss: 0.4153 - acc: 0.8333 - val_loss: 0.1329 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "3492/3492 [==============================] - 1s 194us/step - loss: 0.3591 - acc: 0.8634 - val_loss: 0.1245 - val_acc: 0.9864\n",
      "Epoch 8/10\n",
      "3492/3492 [==============================] - 1s 210us/step - loss: 0.3414 - acc: 0.8666 - val_loss: 0.1128 - val_acc: 0.9864\n",
      "Epoch 9/10\n",
      "3492/3492 [==============================] - 1s 207us/step - loss: 0.3032 - acc: 0.8849 - val_loss: 0.1050 - val_acc: 0.9864\n",
      "Epoch 10/10\n",
      "3492/3492 [==============================] - 1s 222us/step - loss: 0.3039 - acc: 0.8783 - val_loss: 0.0954 - val_acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efba73085c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y, validation_data=(np.array(test_df), y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(SGD(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3492 samples, validate on 514 samples\n",
      "Epoch 1/10\n",
      "Epoch 0 LR = 1.0273866637534177\n",
      "3492/3492 [==============================] - 4s 1ms/step - loss: 0.3512 - acc: 0.8706 - val_loss: 0.8457 - val_acc: 0.7704\n",
      "Epoch 2/10\n",
      "Epoch 1 LR = 0.25070459981503956\n",
      "3492/3492 [==============================] - 1s 258us/step - loss: 0.3301 - acc: 0.8731 - val_loss: 0.0901 - val_acc: 0.9864\n",
      "Epoch 3/10\n",
      "Epoch 2 LR = 0.41183196300523245\n",
      "3492/3492 [==============================] - 1s 241us/step - loss: 0.2761 - acc: 0.8929 - val_loss: 0.0679 - val_acc: 0.9903\n",
      "Epoch 4/10\n",
      "Epoch 3 LR = 0.5928534254239075\n",
      "3492/3492 [==============================] - 1s 269us/step - loss: 0.2332 - acc: 0.9135 - val_loss: 0.0815 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "Epoch 4 LR = 0.49775331026265085\n",
      "3492/3492 [==============================] - 1s 233us/step - loss: 0.1949 - acc: 0.9293 - val_loss: 0.0885 - val_acc: 0.9844\n",
      "Epoch 6/10\n",
      "Epoch 5 LR = 0.605234655008062\n",
      "3492/3492 [==============================] - 1s 252us/step - loss: 0.2200 - acc: 0.9181 - val_loss: 2.0354 - val_acc: 0.0370\n",
      "Epoch 7/10\n",
      "Epoch 6 LR = 0.350319663708589\n",
      "3492/3492 [==============================] - 1s 272us/step - loss: 0.2158 - acc: 0.9144 - val_loss: 0.0753 - val_acc: 0.9903\n",
      "Epoch 8/10\n",
      "Epoch 7 LR = 0.32888708411685136\n",
      "3492/3492 [==============================] - 1s 251us/step - loss: 0.1948 - acc: 0.9241 - val_loss: 0.0426 - val_acc: 0.9942\n",
      "Epoch 9/10\n",
      "Epoch 8 LR = 0.2818006270023818\n",
      "3492/3492 [==============================] - 1s 248us/step - loss: 0.1818 - acc: 0.9293 - val_loss: 0.0829 - val_acc: 0.9844\n",
      "Epoch 10/10\n",
      "Epoch 9 LR = 0.30209584872313133\n",
      "3492/3492 [==============================] - 1s 251us/step - loss: 0.1948 - acc: 0.9184 - val_loss: 0.0143 - val_acc: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efba4379438>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y, validation_data=(np.array(test_df), y_test), epochs=10, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
